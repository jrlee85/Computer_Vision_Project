{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent TensorFlow from allocating all GPU memory\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from tensorflow.keras.callbacks import BaseLogger\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db25ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle truncated images\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4367196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes for benchmark model\n",
    "\n",
    "classes = os.listdir('MOUNT_DIRECTORY/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation for training and validation sets (no augmentation for validation)\n",
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "valAug = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c968648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validatoin directories\n",
    "\n",
    "train_dir = \"MOUNT_DIRECTORY/training\"\n",
    "validation_dir = \"MOUNT_DIRECTORY/validation\"\n",
    "\n",
    "# Use flow_from_directory to create training and validation generators, using batches of images\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    train_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=128)\n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "    validation_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a94069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to save model training progress after specified number of epochs\n",
    "\n",
    "class EpochCheckpoint(Callback):\n",
    "    def __init__(self, outputPath, every=5, startAt=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.outputPath = outputPath\n",
    "        self.every = every\n",
    "        self.intEpoch = startAt\n",
    "  \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (self.intEpoch + 1) % self.every == 0:\n",
    "            p = os.path.sep.join([self.outputPath, \"epoch_{}\".format(self.intEpoch + 1)])\n",
    "            self.model.save(p, overwrite = True)\n",
    "            self.intEpoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177910c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to save and plot metrics during training \n",
    "\n",
    "class TrainingMonitor(BaseLogger):\n",
    "    def __init__(self, figPath, jsonPath=None, startAt=0):\n",
    "        # store the output path for the figure, the path to the JSON\n",
    "        # serialized file, and the starting epoch\n",
    "        super(TrainingMonitor, self).__init__()\n",
    "        self.figPath = figPath\n",
    "        self.jsonPath = jsonPath\n",
    "        self.startAt = startAt\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # initialize the history dictionary\n",
    "        self.H = {}\n",
    "\n",
    "        # if the JSON history path exists, load the training history\n",
    "        if self.jsonPath is not None:\n",
    "            if os.path.exists(self.jsonPath):\n",
    "                self.H = json.loads(open(self.jsonPath).read())\n",
    "\n",
    "                # check to see if a starting epoch was supplied\n",
    "                if self.startAt > 0:\n",
    "                    # loop over the entries in the history log and\n",
    "                    # trim any entries that are past the starting\n",
    "                    # epoch\n",
    "                    for k in self.H.keys():\n",
    "                        self.H[k] = self.H[k][:self.startAt]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # loop over the logs and update the loss, accuracy, etc.\n",
    "        # for the entire training process\n",
    "        for (k, v) in logs.items():\n",
    "            l = self.H.get(k, [])\n",
    "            l.append(float(v))\n",
    "            self.H[k] = l\n",
    "\n",
    "        # check to see if the training history should be serialized\n",
    "        # to file\n",
    "        if self.jsonPath is not None:\n",
    "            f = open(self.jsonPath, \"w\")\n",
    "            f.write(json.dumps(self.H))\n",
    "            f.close()\n",
    "\n",
    "        # ensure at least two epochs have passed before plotting\n",
    "        # (epoch starts at zero)\n",
    "        if len(self.H[\"loss\"]) > 1:\n",
    "            # plot the training loss and accuracy\n",
    "            N = np.arange(0, len(self.H[\"loss\"]))\n",
    "            plt.style.use(\"ggplot\")\n",
    "            plt.figure()\n",
    "            plt.plot(N, self.H[\"loss\"], label=\"train_loss\")\n",
    "            plt.plot(N, self.H[\"val_loss\"], label=\"val_loss\")\n",
    "            plt.plot(N, self.H[\"accuracy\"], label=\"train_acc\")\n",
    "            plt.plot(N, self.H[\"val_accuracy\"], label=\"val_acc\")\n",
    "            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(\n",
    "                len(self.H[\"loss\"])))\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Loss/Accuracy\")\n",
    "            plt.legend()\n",
    "\n",
    "            # save the figure\n",
    "            plt.savefig(self.figPath)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing layer, followed by loading MobileNetV2 architecture with weights learned from ImageNet dataset\n",
    "# Set include_top to false to remove final layers\n",
    "\n",
    "i = tf.keras.layers.Input([None, None, 3], dtype = tf.uint8)\n",
    "x = tf.cast(i, tf.float32)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "core = tf.keras.applications.MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "input_tensor=Input(shape=(224, 224, 3)))\n",
    "# Freeze all layers\n",
    "for layer in core.layers:\n",
    "    layer.trainable = False\n",
    "# Unfreeze final five layers\n",
    "for layer in core.layers[150:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dfb518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add four additional layers to model, specifying output layer size using classes earlier defined\n",
    "\n",
    "x = core(x)\n",
    "baseModel = Model(inputs=[i], outputs=[x])\n",
    "\n",
    "y = baseModel.output\n",
    "y = layers.Flatten()(y)\n",
    "y = layers.Dense(1024, activation='relu')(y)\n",
    "y = layers.Dropout(0.2)(y)\n",
    "y = layers.Dense(len(classes), activation=\"softmax\")(y)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set existing model to None to prevent loading any model and resuming training\n",
    "\n",
    "existing_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with predetermined hyperparameters\n",
    "\n",
    "if existing_model is None:\n",
    "    opt = Adam(learning_rate=1e-4)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"top_k_categorical_accuracy\"])\n",
    "# Provide the option of resuming from an existing model in case training is interrupted\n",
    "else:\n",
    "    model = load_model(existing_model)\n",
    "    K.set_value(model.optimizer.learning_rate, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b77e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define checkpoints and starting epoch to be used by callback when saving models and performance\n",
    "\n",
    "checkpoints = \"MOUNT_DIRECTORY/output/checkpoints\"\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed06014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define location for callbacks to save performance \n",
    "\n",
    "plotPath = os.path.sep.join([\"MOUNT_DIRECTORY/output/\", \"benchmark.png\"])\n",
    "jsonPath = os.path.sep.join([\"MOUNT_DIRECTORY/output/\", \"benchmark.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks so as to save model after every epoch\n",
    "\n",
    "callbacks = [\n",
    "    EpochCheckpoint(checkpoints, every=1,\n",
    "        startAt=start_epoch),\n",
    "    TrainingMonitor(plotPath,\n",
    "        jsonPath=jsonPath,\n",
    "        startAt=start_epoch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train benchmark model\n",
    "\n",
    "history = model.fit(\n",
    "    trainGen,\n",
    "    validation_data=valGen,\n",
    "    epochs=50,\n",
    "  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bd9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes for family model\n",
    "\n",
    "family_classes = os.listdir('MOUNT_DIRECTORY/family_data/training_family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad96c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear existing training and validatoin generators\n",
    "\n",
    "trainGen.reset()\n",
    "valGen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new generators for the family model\n",
    "\n",
    "train_dir = 'MOUNT_DIRECTORY/family_data/training_family'\n",
    "validation_dir = \"MOUNT_DIRECTORY/family_data/validation_family\"\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    train_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=128)\n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "    validation_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759485e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat model building process for family model, using family classes for output\n",
    "\n",
    "i = tf.keras.layers.Input([None, None, 3], dtype = tf.uint8)\n",
    "x = tf.cast(i, tf.float32)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "core = tf.keras.applications.MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "input_tensor=Input(shape=(224, 224, 3)))\n",
    "for layer in core.layers:\n",
    "    layer.trainable = False\n",
    "for layer in core.layers[150:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "x = core(x)\n",
    "baseModel = Model(inputs=[i], outputs=[x])\n",
    "\n",
    "y = baseModel.output\n",
    "y = layers.Flatten()(y)\n",
    "y = layers.Dense(1024, activation='relu')(y)\n",
    "y = layers.Dropout(0.2)(y)\n",
    "y = layers.Dense(len(family_classes), activation=\"softmax\")(y)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acef1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if existing_model is None:\n",
    "    opt = Adam(learning_rate=1e-4, decay=1e-4 / 50)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"top_k_categorical_accuracy\"])\n",
    "else:\n",
    "    model = load_model(existing_model)\n",
    "    K.set_value(model.optimizer.learning_rate, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = \"MOUNT_DIRECTORY/family_data/output/checkpoints\"\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPath = os.path.sep.join([\"MOUNT_DIRECTORY/family_data/output/\", \"family.png\"])\n",
    "jsonPath = os.path.sep.join([\"MOUNT_DIRECTORY/family_data/output/\", \"family.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa10873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train family model\n",
    "\n",
    "history = model.fit(\n",
    "    trainGen,\n",
    "    validation_data=valGen,\n",
    "    epochs=50,\n",
    "  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load benchmark model from best epoch\n",
    "\n",
    "benchmark_model = load_model('MOUNT_DIRECTORY/output/checkpoints/epoch_48')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770139dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test generator (again without data augmentation) to evaluate model performance\n",
    "\n",
    "test_dir = 'MOUNT_DIRECTORY/test'\n",
    "\n",
    "testGen = valAug.flow_from_directory(\n",
    "    test_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate bechmark model and save scores to csv file \n",
    "\n",
    "benchmark_score = benchmark_model.evaluate(testGen)\n",
    "print(\"Evaluation finished\")\n",
    "benchmark_score_df = pd.DataFrame({'Loss':benchmark_score[0], 'Top-1-Accuracy':benchmark_score[1], \n",
    "                                   'Top-5-Accuracy':benchmark_score[2]}, index=['Performance'])\n",
    "benchmark_score_df.to_csv('MOUNT_DIRECTORY/output/benchmark_score.csv')\n",
    "benchmark_predIdxs = benchmark_model.predict(x=testGen)\n",
    "print(\"Predictions finished\")\n",
    "benchmark_predIdxs = np.argmax(benchmark_predIdxs, axis=1)\n",
    "# Use scikit-learn classificatoin report to create and save csv file of precision, recall and F1-score\n",
    "benchmark_report = classification_report(testGen.classes, benchmark_predIdxs,\n",
    "                                         target_names=testGen.class_indices.keys(), output_dict=True)\n",
    "df = pd.DataFrame(benchmark_report).transpose()\n",
    "df.to_csv('MOUNT_DIRECTORY/output/benchmark_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d48fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create (and save) dataframe of incorrect predictions along with file names \n",
    "\n",
    "benchmark_mistakes = pd.DataFrame.from_dict({\"Prediction\": benchmark_predIdxs, \"Actual\": testGen.classes})\n",
    "benchmark_mistakes.to_csv('MOUNT_DIRECTORY/output/benchmark_mistakes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat process with out-of-sample data\n",
    "\n",
    "oos_dir = 'MOUNT_DIRECTORY/out_of_sample'\n",
    "\n",
    "oosGen = valAug.flow_from_directory(\n",
    "    oos_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_oos_score = benchmark_model.evaluate(oosGen)\n",
    "print(\"Evaluation finished\")\n",
    "benchmark_oos_score_df = pd.DataFrame({'Loss':benchmark_oos_score[0], 'Top-1-Accuracy':benchmark_oos_score[1], \n",
    "                                       'Top-5-Accuracy':benchmark_oos_score[2]}, index=['Performance'])\n",
    "benchmark_oos_score_df.to_csv('MOUNT_DIRECTORY/output/benchmark_oos_score.csv')\n",
    "benchmark_oos_predIdxs = benchmark_model.predict(x=oosGen)\n",
    "print(\"Predictions finished\")\n",
    "benchmark_oos_predIdxs = np.argmax(benchmark_oos_predIdxs, axis=1)\n",
    "# Necessary to define labels, otherwise dataframe dimensions do not match\n",
    "benchmark_oos_report = classification_report(oosGen.classes, benchmark_oos_predIdxs,\n",
    "                                labels = list(range(0,79)), target_names=oosGen.class_indices.keys(), output_dict=True)\n",
    "df = pd.DataFrame(benchmark_oos_report).transpose()\n",
    "df.to_csv('MOUNT_DIRECTORY/output/benchmark_oos_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17663f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out-of-sample mistakes\n",
    "\n",
    "benchmark_oos_mistakes = pd.DataFrame.from_dict({\"Prediction\": benchmark_oos_predIdxs, \"Actual\": oosGen.classes})\n",
    "benchmark_oos_mistakes.to_csv('MOUNT_DIRECTORY/output/benchmark_oos_mistakes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b957d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat process with family model\n",
    "\n",
    "family_model = load_model('MOUNT_DIRECTORY/family_data/output/checkpoints/epoch_45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "testGen.reset()\n",
    "\n",
    "test_dir = 'MOUNT_DIRECTORY/family_data/test_family'\n",
    "\n",
    "testGen = valAug.flow_from_directory(\n",
    "    test_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea91724",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_score = family_model.evaluate(testGen)\n",
    "print(\"Evaluation finished\")\n",
    "score_df = pd.DataFrame({'Loss':family_score[0], 'Top-1-Accuracy':family_score[1], 'Top-5-Accuracy':family_score[2]}, \n",
    "                        index=['Performance'])\n",
    "score_df.to_csv('MOUNT_DIRECTORY/family_data/output/score.csv')\n",
    "family_predIdxs = family_model.predict(x=testGen)\n",
    "print(\"Predictions finished\")\n",
    "family_predIdxs = np.argmax(family_predIdxs, axis=1)\n",
    "report = classification_report(testGen.classes, family_predIdxs, target_names=testGen.class_indices.keys(), \n",
    "                               output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv('MOUNT_DIRECTORY/family_data/output/evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define felinae classes in order to build felinae model\n",
    "\n",
    "felinae_classes = os.listdir('MOUNT_DIRECTORY/felinae/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f624f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat process to create generators for felinae model\n",
    "\n",
    "trainGen.reset()\n",
    "valGen.reset()\n",
    "\n",
    "train_dir = 'MOUNT_DIRECTORY/felinae/training'\n",
    "validation_dir = \"MOUNT_DIRECTORY/felinae/validation\"\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    train_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=128)\n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "    validation_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3322abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load family model (instead of pretrained MobileNetV2)\n",
    "\n",
    "model = load_model('MOUNT_DIRECTORY/family_data/output/checkpoints/epoch_45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b47c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace last layer using felinae classes\n",
    "\n",
    "felinae_model= Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "y = felinae_model.output\n",
    "y = layers.Dense(len(felinae_classes), activation=\"softmax\")(y)\n",
    "felinae_model = Model(inputs=felinae_model.input, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat training process\n",
    "\n",
    "existing_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c89171",
   "metadata": {},
   "outputs": [],
   "source": [
    "if existing_model is None:\n",
    "    opt = Adam(learning_rate=1e-4, decay=1e-4 / 50)\n",
    "    felinae_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, \n",
    "                          metrics=[\"accuracy\", \"top_k_categorical_accuracy\"])\n",
    "else:\n",
    "    model = load_model(existing_model)\n",
    "    K.set_value(model.optimizer.learning_rate, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce360385",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = \"MOUNT_DIRECTORY/felinae/output/checkpoints\"\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37daf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPath = os.path.sep.join([\"MOUNT_DIRECTORY/felinae/output/\", \"felinae.png\"])\n",
    "jsonPath = os.path.sep.join([\"MOUNT_DIRECTORY/felinae/output/\", \"feliane.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deccc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EpochCheckpoint(checkpoints, every=1,\n",
    "        startAt=start_epoch),\n",
    "    TrainingMonitor(plotPath,\n",
    "        jsonPath=jsonPath,\n",
    "        startAt=start_epoch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fedef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = felinae_model.fit(\n",
    "    trainGen,\n",
    "    validation_data=valGen,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8334d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat process for canidae and sciuridae models\n",
    "\n",
    "canidae_classes = os.listdir('MOUNT_DIRECTORY/canidae/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13006b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGen.reset()\n",
    "valGen.reset()\n",
    "\n",
    "train_dir = 'MOUNT_DIRECTORY/canidae/training'\n",
    "validation_dir = \"MOUNT_DIRECTORY/canidae/validation\"\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    train_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=128)\n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "    validation_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('MOUNT_DIRECTORY/family_data/output/checkpoints/epoch_45')\n",
    "canidae_model= Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "y = canidae_model.output\n",
    "y = layers.Dense(len(canidae_classes), activation=\"softmax\")(y)\n",
    "canidae_model = Model(inputs=canidae_model.input, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e731b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e03201",
   "metadata": {},
   "outputs": [],
   "source": [
    "if existing_model is None:\n",
    "    opt = Adam(learning_rate=1e-4, decay=1e-4 / 50)\n",
    "    canidae_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, \n",
    "                          metrics=[\"accuracy\", \"top_k_categorical_accuracy\"])\n",
    "else:\n",
    "    canidae_model = load_model(existing_model)\n",
    "    K.set_value(canidae_model.optimizer.learning_rate, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = \"MOUNT_DIRECTORY/canidae/output/checkpoints\"\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248089bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPath = os.path.sep.join([\"MOUNT_DIRECTORY/canidae/output/\", \"canidae.png\"])\n",
    "jsonPath = os.path.sep.join([\"MOUNT_DIRECTORY/canidae/output/\", \"canidae.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EpochCheckpoint(checkpoints, every=1,\n",
    "        startAt=start_epoch),\n",
    "    TrainingMonitor(plotPath,\n",
    "        jsonPath=jsonPath,\n",
    "        startAt=start_epoch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = canidae_model.fit(\n",
    "    trainGen,\n",
    "    validation_data=valGen,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciuridae_classes = os.listdir('MOUNT_DIRECTORY/sciuridae/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6397e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGen.reset()\n",
    "valGen.reset()\n",
    "\n",
    "train_dir = 'MOUNT_DIRECTORY/sciuridae/training'\n",
    "validation_dir = \"MOUNT_DIRECTORY/sciuridae/validation\"\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    train_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=128)\n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "    validation_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('MOUNT_DIRECTORY/family_data/output/checkpoints/epoch_45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ce9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciuridae_model= Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "y = sciuridae_model.output\n",
    "y = layers.Dense(len(sciuridae_classes), activation=\"softmax\")(y)\n",
    "sciuridae_model = Model(inputs=sciuridae_model.input, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875495db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if existing_model is None:\n",
    "    opt = Adam(learning_rate=1e-4, decay=1e-4 / 50)\n",
    "    sciuridae_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, \n",
    "                            metrics=[\"accuracy\", \"top_k_categorical_accuracy\"])\n",
    "else:\n",
    "    sciuridae_model = load_model(existing_model)\n",
    "    K.set_value(sciuridae_model.optimizer.learning_rate, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e5f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = \"MOUNT_DIRECTORY/sciuridae/output/checkpoints\"\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPath = os.path.sep.join([\"MOUNT_DIRECTORY/sciuridae/output/\", \"sciuridae.png\"])\n",
    "jsonPath = os.path.sep.join([\"MOUNT_DIRECTORY/sciuridae/output/\", \"sciuridae.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3143b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EpochCheckpoint(checkpoints, every=1,\n",
    "        startAt=start_epoch),\n",
    "    TrainingMonitor(plotPath,\n",
    "        jsonPath=jsonPath,\n",
    "        startAt=start_epoch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b1a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = sciuridae_model.fit(\n",
    "    trainGen,\n",
    "    validation_data=valGen,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a7da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load felinae model from best epoch, then repeat model evaluation process\n",
    "\n",
    "felinae_model = load_model('MOUNT_DIRECTORY/felinae/output/checkpoints/epoch_40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "testGen.reset()\n",
    "\n",
    "felinae_test_dir = 'MOUNT_DIRECTORY/felinae/test'\n",
    "\n",
    "felinae_testGen = valAug.flow_from_directory(\n",
    "    felinae_test_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c3b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "felinae_score = felinae_model.evaluate(felinae_testGen)\n",
    "print(\"Evaluation finished\")\n",
    "felinae_score_df = pd.DataFrame({'Loss':felinae_score[0], 'Top-1-Accuracy':felinae_score[1], \n",
    "                                 'Top-5-Accuracy':felinae_score[2]}, index=['Performance'])\n",
    "felinae_score_df.to_csv('MOUNT_DIRECTORY/felinae/output/felinae_score.csv')\n",
    "felinae_predIdxs = felinae_model.predict(x=felinae_testGen)\n",
    "print(\"Predictions finished\")\n",
    "felinae_predIdxs = np.argmax(felinae_predIdxs, axis=1)\n",
    "felinae_report = classification_report(felinae_testGen.classes, felinae_predIdxs,\n",
    "                                       target_names=felinae_testGen.class_indices.keys(), output_dict=True)\n",
    "df = pd.DataFrame(felinae_report).transpose()\n",
    "df.to_csv('MOUNT_DIRECTORY/felinae/output/felinae_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "felinae_mistakes = pd.DataFrame.from_dict({\"Prediction\": felinae_predIdxs, \"Actual\": felinae_testGen.classes})\n",
    "felinae_mistakes.to_csv('MOUNT_DIRECTORY/felinae/output/felinae_mistakes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d61e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "felinae_oos_dir = 'MOUNT_DIRECTORY/felinae/out_of_sample'\n",
    "\n",
    "felinae_oosGen = valAug.flow_from_directory(\n",
    "    felinae_oos_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9276756",
   "metadata": {},
   "outputs": [],
   "source": [
    "felinae_oos_score = felinae_model.evaluate(felinae_oosGen)\n",
    "print(\"Evaluation finished\")\n",
    "felinae_oos_score_df = pd.DataFrame({'Loss':felinae_oos_score[0], 'Top-1-Accuracy':felinae_oos_score[1], \n",
    "                                     'Top-5-Accuracy':felinae_oos_score[2]}, index=['Performance'])\n",
    "felinae_oos_score_df.to_csv('MOUNT_DIRECTORY/felinae/output/felinae_oos_score.csv')\n",
    "felinae_oos_predIdxs = felinae_model.predict(x=felinae_oosGen)\n",
    "print(\"Predictions finished\")\n",
    "felinae_oos_predIdxs = np.argmax(felinae_oos_predIdxs, axis=1)\n",
    "felinae_oos_report = classification_report(felinae_oosGen.classes, felinae_oos_predIdxs,\n",
    "                            labels = (0,1,2,3,4,5), target_names=felinae_oosGen.class_indices.keys(), output_dict=True)\n",
    "df = pd.DataFrame(felinae_oos_report).transpose()\n",
    "df.to_csv('MOUNT_DIRECTORY/felinae/output/felinae_oos_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "felinae_oos_mistakes = pd.DataFrame.from_dict({\"Prediction\": felinae_oos_predIdxs, \"Actual\": felinae_oosGen.classes})\n",
    "felinae_oos_mistakes.to_csv('MOUNT_DIRECTORY/felinae/output/felinae_oos_mistakes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b741070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for Canidae and Sciuridae models\n",
    "\n",
    "canidae_model = load_model('MOUNT_DIRECTORY/canidae/output/checkpoints/epoch_43')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testGen.reset()\n",
    "\n",
    "canidae_test_dir = 'MOUNT_DIRECTORY/canidae/test'\n",
    "\n",
    "canidae_testGen = valAug.flow_from_directory(\n",
    "    canidae_test_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "canidae_score = canidae_model.evaluate(canidae_testGen)\n",
    "print(\"Evaluation finished\")\n",
    "canidae_score_df = pd.DataFrame({'Loss':canidae_score[0], 'Top-1-Accuracy':canidae_score[1], \n",
    "                                 'Top-5-Accuracy':canidae_score[2]}, index=['Performance'])\n",
    "canidae_score_df.to_csv('MOUNT_DIRECTORY/canidae/output/canidae_score.csv')\n",
    "canidae_predIdxs = canidae_model.predict(x=canidae_testGen)\n",
    "print(\"Predictions finished\")\n",
    "canidae_predIdxs = np.argmax(canidae_predIdxs, axis=1)\n",
    "canidae_report = classification_report(canidae_testGen.classes, canidae_predIdxs,\n",
    "                                       target_names=canidae_testGen.class_indices.keys(), output_dict=True)\n",
    "df = pd.DataFrame(canidae_report).transpose()\n",
    "df.to_csv('MOUNT_DIRECTORY/canidae/output/canidae_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c0874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "canidae_mistakes = pd.DataFrame.from_dict({\"Prediction\": canidae_predIdxs, \"Actual\": canidae_testGen.classes})\n",
    "canidae_mistakes.to_csv('MOUNT_DIRECTORY/canidae/output/canidae_mistakes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "canidae_oos_dir = 'MOUNT_DIRECTORY/canidae/out_of_sample'\n",
    "\n",
    "canidae_oosGen = valAug.flow_from_directory(\n",
    "    canidae_oos_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88741bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "canidae_oos_score = canidae_model.evaluate(canidae_oosGen)\n",
    "print(\"Evaluation finished\")\n",
    "canidae_oos_score_df = pd.DataFrame({'Loss':canidae_oos_score[0], 'Top-1-Accuracy':canidae_oos_score[1], \n",
    "                                     'Top-5-Accuracy':canidae_oos_score[2]}, index=['Performance'])\n",
    "canidae_oos_score_df.to_csv('MOUNT_DIRECTORY/canidae/output/canidae_oos_score.csv')\n",
    "canidae_oos_predIdxs = canidae_model.predict(x=canidae_oosGen)\n",
    "print(\"Predictions finished\")\n",
    "canidae_oos_predIdxs = np.argmax(canidae_oos_predIdxs, axis=1)\n",
    "canidae_oos_report = classification_report(canidae_oosGen.classes, canidae_oos_predIdxs,\n",
    "                            labels = (0,1,2,3,4,5), target_names=canidae_oosGen.class_indices.keys(), output_dict=True)\n",
    "df = pd.DataFrame(canidae_oos_report).transpose()\n",
    "df.to_csv('MOUNT_DIRECTORY/canidae/output/canidae_oos_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285cb782",
   "metadata": {},
   "outputs": [],
   "source": [
    "canidae_oos_mistakes = pd.DataFrame.from_dict({\"Prediction\": canidae_oos_predIdxs, \"Actual\": canidae_oosGen.classes})\n",
    "canidae_oos_mistakes.to_csv('MOUNT_DIRECTORY/canidae/output/canidae_oos_mistakes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693df2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciuridae_model = load_model('MOUNT_DIRECTORY/sciuridae/output/checkpoints/epoch_35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80510729",
   "metadata": {},
   "outputs": [],
   "source": [
    "testGen.reset()\n",
    "\n",
    "sciuridae_test_dir = 'MOUNT_DIRECTORY/sciuridae/test'\n",
    "\n",
    "sciuridae_testGen = valAug.flow_from_directory(\n",
    "    sciuridae_test_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad770c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciuridae_score = sciuridae_model.evaluate(sciuridae_testGen)\n",
    "print(\"Evaluation finished\")\n",
    "sciuridae_score_df = pd.DataFrame({'Loss':sciuridae_score[0], 'Top-1-Accuracy':sciuridae_score[1], \n",
    "                                   'Top-5-Accuracy':sciuridae_score[2]}, index=['Performance'])\n",
    "sciuridae_score_df.to_csv('MOUNT_DIRECTORY/sciuridae/output/sciuridae_score.csv')\n",
    "sciuridae_predIdxs = sciuridae_model.predict(x=sciuridae_testGen)\n",
    "print(\"Predictions finished\")\n",
    "sciuridae_predIdxs = np.argmax(sciuridae_predIdxs, axis=1)\n",
    "sciuridae_report = classification_report(sciuridae_testGen.classes, sciuridae_predIdxs,\n",
    "                                         target_names=sciuridae_testGen.class_indices.keys(), output_dict=True)\n",
    "df = pd.DataFrame(sciuridae_report).transpose()\n",
    "df.to_csv('MOUNT_DIRECTORY/sciuridae/output/sciuridae_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciuridae_mistakes = pd.DataFrame.from_dict({\"Prediction\": sciuridae_predIdxs, \"Actual\": sciuridae_testGen.classes})\n",
    "sciuridae_mistakes.to_csv('MOUNT_DIRECTORY/sciuridae/output/sciuridae_mistakes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciuridae_oos_dir = 'MOUNT_DIRECTORY/sciuridae/out_of_sample'\n",
    "\n",
    "sciuridae_oosGen = valAug.flow_from_directory(\n",
    "    sciuridae_oos_dir,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b056554",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciuridae_oos_score = sciuridae_model.evaluate(sciuridae_oosGen)\n",
    "print(\"Evaluation finished\")\n",
    "sciuridae_oos_score_df = pd.DataFrame({'Loss':sciuridae_oos_score[0], 'Top-1-Accuracy':sciuridae_oos_score[1], \n",
    "                                       'Top-5-Accuracy':sciuridae_oos_score[2]}, index=['Performance'])\n",
    "sciuridae_oos_score_df.to_csv('MOUNT_DIRECTORY/sciuridae/output/sciuridae_oos_score.csv')\n",
    "sciuridae_oos_predIdxs = sciuridae_model.predict(x=sciuridae_oosGen)\n",
    "print(\"Predictions finished\")\n",
    "sciuridae_oos_predIdxs = np.argmax(sciuridae_oos_predIdxs, axis=1)\n",
    "sciuridae_oos_report = classification_report(sciuridae_oosGen.classes, sciuridae_oos_predIdxs, \n",
    "                        labels = (0,1,2,3,4,5), target_names=sciuridae_oosGen.class_indices.keys(), output_dict=True)\n",
    "df = pd.DataFrame(sciuridae_oos_report).transpose()\n",
    "df.to_csv('MOUNT_DIRECTORY/sciuridae/output/sciuridae_oos_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciuridae_oos_mistakes = pd.DataFrame.from_dict({\"Prediction\": sciuridae_oos_predIdxs, \n",
    "                                                 \"Actual\": sciuridae_oosGen.classes})\n",
    "sciuridae_oos_mistakes.to_csv('MOUNT_DIRECTORY/sciuridae/output/sciuridae_oos_mistakes.csv')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
